{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYXIHngPoI2W"
      },
      "source": [
        "# Neural Machine Translation with Sequence Models\n",
        "\n",
        "This notebook implements and compares several sequence-to-sequence models for English-to-German neural machine translation using PyTorch and TorchText. It includes classic RNN-based architectures (LSTM with and without attention) as well as a Transformer model.\n",
        "\n",
        "The primary goals of this project are:\n",
        "- To explore the effectiveness of various encoder-decoder architectures for translation tasks\n",
        "- To assess the impact of attention mechanisms and transformer-based modeling\n",
        "- To evaluate translation quality using PPL (Perplexity) and BLEU scores\n",
        "\n",
        "Models Trained:\n",
        "- LSTM-based Seq2Seq\n",
        "- LSTM with Attention\n",
        "- Transformer (full architecture)\n",
        "\n",
        "Evaluation is done using the BLEU metric on the Multi30k English-German dataset, and translation examples are provided for qualitative analysis.\n",
        "\n",
        "\n",
        "The dataset used is the Multi30k English-German translation corpus. This notebook also handles full data preprocessing, tokenization with SpaCy, custom training loops, and a framework for evaluating translation quality qualitatively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0HEy2Tok-2u",
        "outputId": "461d7f0e-2b07-41d2-936c-981203b4eb55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "# Setup: Mount Google Drive to access data for NMT model training\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHzfVbfmloDz"
      },
      "outputs": [],
      "source": [
        "# Set the directory path where the NMT project notebook is located.\n",
        "# For example, if the notebook is saved in '/gdrive/MyDrive/NMTproject', set:\n",
        "root = '/gdrive/MyDrive/NMTproject'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpWbZsp2quKI",
        "outputId": "523bd295-3e84-42ba-b213-4412a12c9138"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.31.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Collecting sentencepiece (from torchtext==0.6.0)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.16.0\n",
            "    Uninstalling torchtext-0.16.0:\n",
            "      Successfully uninstalled torchtext-0.16.0\n",
            "Successfully installed sentencepiece-0.1.99 torchtext-0.6.0\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "2023-11-21 13:45:56.780004: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-21 13:45:56.780065: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-21 13:45:56.780104: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-21 13:45:56.790978: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-21 13:45:58.527322: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-11-21 13:46:00.414250: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-21 13:46:00.414750: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-21 13:46:00.414953: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "2023-11-21 13:46:13.574794: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-21 13:46:13.574850: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-21 13:46:13.574887: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-21 13:46:13.586211: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-21 13:46:15.232733: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-11-21 13:46:16.865482: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-21 13:46:16.865895: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-21 13:46:16.866062: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'de' are deprecated. Please use the\n",
            "full pipeline package name 'de_core_news_sm' instead.\u001b[0m\n",
            "Collecting de-core-news-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.6.0/de_core_news_sm-3.6.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.1.3)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext==0.6.0\n",
        "!pip install spacy\n",
        "!python -m spacy download en\n",
        "!python -m spacy download de"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGlC_yM9lvue"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries for Neural Machine Translation (NMT)\n",
        "# PyTorch for model building and training\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.parameter import Parameter\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import SGD\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# TorchText for dataset handling, tokenization, and language processing\n",
        "import torchtext\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "# SpaCy for additional tokenization and preprocessing\n",
        "import spacy\n",
        "from spacy.symbols import ORTH\n",
        "\n",
        "# Other utilities for general project setup\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "import math\n",
        "from pathlib import Path\n",
        "import tqdm.notebook as tq\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dczwhJI1l8Kl"
      },
      "outputs": [],
      "source": [
        "# Set up basic configurations and hyperparameters for NMT models\n",
        "# Fix random seed for reproducibility\n",
        "torch.manual_seed(470)\n",
        "torch.cuda.manual_seed(470)\n",
        "\n",
        "from easydict import EasyDict as edict\n",
        "\n",
        "# Model training hyperparameters\n",
        "args = edict()\n",
        "args.batch_size = 32\n",
        "args.nlayers = 2\n",
        "args.ninp = 256\n",
        "args.nhid = 256\n",
        "args.clip = 1\n",
        "args.lr_lstm = 0.001\n",
        "args.dropout = 0.2\n",
        "args.nhid_attn = 256\n",
        "args.epochs = 20\n",
        "\n",
        "# Transformer-specific parameters\n",
        "args.nhid_tran = 256\n",
        "args.nhead = 8\n",
        "args.nlayers_transformer = 6\n",
        "args.attn_pdrop = 0.1\n",
        "args.resid_pdrop = 0.1\n",
        "args.embd_pdrop = 0.1\n",
        "args.nff = 4 * args.nhid_tran\n",
        "\n",
        "args.lr_transformer = 0.0001  # Learning rate for Transformer model\n",
        "args.betas = (0.9, 0.98)\n",
        "\n",
        "args.gpu = True\n",
        "device = 'cuda:0' if torch.cuda.is_available() and args.gpu else 'cpu'\n",
        "\n",
        "# Create a directory to save results\n",
        "result_dir = Path(root) / 'results'\n",
        "result_dir.mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUOvr2A_mf4Q"
      },
      "outputs": [],
      "source": [
        "# Converts a sequence of word ids to a sentence (denumericalization)\n",
        "def word_ids_to_sentence(id_tensor, vocab, join=' '):\n",
        "    if isinstance(id_tensor, torch.LongTensor):\n",
        "        ids = id_tensor.transpose(0, 1).contiguous().view(-1)\n",
        "    elif isinstance(id_tensor, np.ndarray):\n",
        "        ids = id_tensor.transpose().reshape(-1)\n",
        "    batch = [vocab.itos[ind] for ind in ids] # denumericalize\n",
        "    if join is None:\n",
        "        return batch\n",
        "    else:\n",
        "        return join.join(batch)\n",
        "\n",
        "# Extracts bias and non-bias parameters from a model for optimization\n",
        "def get_parameters(model, bias=False):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Linear):\n",
        "            if bias:\n",
        "                yield m.bias\n",
        "            else:\n",
        "                yield m.weight\n",
        "        else:\n",
        "            if not bias:\n",
        "                yield m.parameters()\n",
        "\n",
        "# Runs a single training or evaluation epoch\n",
        "# Computes loss, accuracy, and updates model parameters during training\n",
        "def run_epoch(epoch, model, optimizer, is_train=True, data_iter=None):\n",
        "    total_loss = 0\n",
        "    n_correct = 0\n",
        "    n_total = 0\n",
        "    if data_iter is None:\n",
        "        data_iter = train_iter if is_train else valid_iter\n",
        "    if is_train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "    for batch in data_iter:\n",
        "        x, y, length = sort_batch(batch.src.to(device), batch.trg.to(device))\n",
        "        target = y[1:]\n",
        "        if isinstance(model, Transformer):\n",
        "            x, y = x.transpose(0, 1), y.transpose(0, 1)\n",
        "            target = target.transpose(0, 1) #y[:, 1:]\n",
        "        pred = model(x, y, length)\n",
        "        loss = criterion(pred.reshape(-1, trg_ntoken), target.reshape(-1))\n",
        "        n_targets = (target != pad_id).long().sum().item()\n",
        "        n_total += n_targets\n",
        "        target = target.unsqueeze(0)\n",
        "        n_correct += (pred.argmax(-1) == target)[target != pad_id].long().sum().item()\n",
        "        if is_train:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
        "            optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * n_targets\n",
        "    total_loss /= n_total\n",
        "    print(\"Epoch\", epoch, 'Train' if is_train else 'Valid',\n",
        "          \"Loss\", np.mean(total_loss),\n",
        "          \"Acc\", n_correct / n_total,\n",
        "          \"PPL\", np.exp(total_loss))\n",
        "    return total_loss\n",
        "\n",
        "# Converts word ids to sentence, stops at the EOS token\n",
        "def word_ids_to_sentence_(ids, vocab):\n",
        "    sentence = []\n",
        "    for ind in ids:\n",
        "        if ind == eos_id:\n",
        "            break\n",
        "        sentence.append(vocab.itos[ind])\n",
        "    return sentence\n",
        "\n",
        "# Runs the translation process and outputs translation examples\n",
        "# Computes BLEU score for the translated outputs\n",
        "def run_translation(model, data_iter, max_len=100, mode='best'):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        load_model(model, mode)\n",
        "        src_list = []\n",
        "        gt_list = []\n",
        "        pred_list = []\n",
        "        for batch in data_iter:\n",
        "            x, y, length = sort_batch(batch.src.to(device), batch.trg.to(device))\n",
        "            target = y[1:]\n",
        "            if isinstance(model, Transformer):\n",
        "                x, y = x.transpose(0, 1), y.transpose(0, 1)\n",
        "                target = target.transpose(0, 1)\n",
        "            pred = model(x, y, length, max_len=max_len, teacher_forcing=False)\n",
        "            pred_token = pred.argmax(-1)\n",
        "            if not isinstance(model, Transformer):\n",
        "                pred_token = pred_token.transpose(0, 1).cpu().numpy()\n",
        "                y = y.transpose(0, 1).cpu().numpy()\n",
        "                x = x.transpose(0, 1).cpu().numpy()\n",
        "            # pred_token : batch_size x max_len\n",
        "            for x_, y_, pred_ in zip(x, y, pred_token):\n",
        "                src_list.append(word_ids_to_sentence_(x_[1:], SRC.vocab))\n",
        "                gt_list.append([word_ids_to_sentence_(y_[1:], TRG.vocab)])\n",
        "                pred_list.append(word_ids_to_sentence_(pred_, TRG.vocab))\n",
        "\n",
        "        for i in range(5):\n",
        "            print(f\"--------- Translation Example {i+1} ---------\")\n",
        "            print(\"SRC :\", ' '.join(src_list[i]))\n",
        "            print(\"TRG :\", ' '.join(gt_list[i][0]))\n",
        "            print(\"PRED:\", ' '.join(pred_list[i]))\n",
        "        print()\n",
        "        print(\"BLEU:\", bleu_score(pred_list, gt_list))\n",
        "\n",
        "# Saves the model's state_dict to a checkpoint\n",
        "def save_model(model, mode=\"last\"):\n",
        "    torch.save(model.state_dict(),  result_dir / f'{type(model).__name__}_{mode}.ckpt')\n",
        "\n",
        "# Loads a model's state_dict from a checkpoint\n",
        "def load_model(model, mode=\"last\"):\n",
        "    if os.path.exists(result_dir / f'{type(model).__name__}_{mode}.ckpt'):\n",
        "        model.load_state_dict(torch.load(result_dir / f'{type(model).__name__}_{mode}.ckpt'))\n",
        "\n",
        "# Sorts the batch by sequence length (for padding)\n",
        "def sort_batch(X, y, lengths=None):\n",
        "    if lengths is None:\n",
        "        lengths = (X != pad_id_src).long().sum(0)\n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = torch.index_select(X, 1, indx)\n",
        "    y = torch.index_select(y, 1, indx)\n",
        "    return X, y, lengths\n",
        "\n",
        "# Initializes weights for a model's parameters using uniform distribution\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HFB7-CvgFYh"
      },
      "outputs": [],
      "source": [
        "# Manually fix Multi30K download link, since the original server is down. (https://github.com/pytorch/text/issues/1756)\n",
        "Multi30k.urls = [\n",
        "    \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\",\n",
        "    \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\",\n",
        "    \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/mmt16_task1_test.tar.gz\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deEP6JnaywMV",
        "outputId": "f3db98e5-774c-49f3-f615-d6b94c2d68c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "downloading training.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:00<00:00, 9.63MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 2.78MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "downloading mmt16_task1_test.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "mmt16_task1_test.tar.gz: 100%|██████████| 67.1k/67.1k [00:00<00:00, 3.35MB/s]\n"
          ]
        }
      ],
      "source": [
        "SRC = Field(tokenize = \"spacy\",\n",
        "            tokenizer_language=\"de_core_news_sm\",\n",
        "            init_token = '<sos>',\n",
        "            eos_token = '<eos>',\n",
        "            lower = True)\n",
        "\n",
        "TRG = Field(tokenize = \"spacy\",\n",
        "            tokenizer_language=\"en_core_web_sm\",\n",
        "            init_token = '<sos>',\n",
        "            eos_token = '<eos>',\n",
        "            lower = True)\n",
        "\n",
        "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'),\n",
        "                                                    fields = (SRC, TRG), test='test')\n",
        "SRC.build_vocab(train_data, min_freq = 2)\n",
        "TRG.build_vocab(train_data, min_freq = 2)\n",
        "\n",
        "src_ntoken = len(SRC.vocab.stoi)\n",
        "trg_ntoken = len(TRG.vocab.stoi)\n",
        "\n",
        "train_iter, valid_iter, test_iter = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = args.batch_size,\n",
        "    device = device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSAnejfCywMZ",
        "outputId": "78e8dcc0-91fe-4022-da31-68f3b97fea9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([31, 22, 22, 21, 21, 17, 17, 17, 16, 15, 15, 15, 14, 13, 13, 13, 13, 12,\n",
            "        12, 12, 12, 11, 11, 11, 11, 11, 10, 10, 10,  9,  9,  8],\n",
            "       device='cuda:0')\n",
            "tensor([[   2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
            "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
            "            2,    2,    2,    2,    2,    2,    2,    2],\n",
            "        [ 766,    5,    8,    5,   27,    8,   18,    5,    5,    5,    5,    5,\n",
            "            5,    5,    5,    5,    5,    5,    5,    8,    5,   18,    5,   43,\n",
            "            5,   39,    5,   18,    7,   18,    8,   18],\n",
            "        [ 800,   13,   22,   13,    6,  274,   30,   13,   13,   96,   96,   13,\n",
            "           49,   49,   70,   13,  271,   25,  272,  168,    0,  890,   13,  103,\n",
            "          130,   25,   13,  103, 6458,   25,   67,   73],\n",
            "        [  41,    7, 5475,  159,  574,   16,    9,   29,    7,   13,   13,    7,\n",
            "            9,   11,   26,    7,  229,   12,   13,  113,   13,   45,   69,   80,\n",
            "          533, 1899,   11,   80,   84,   53,   37,  141],\n",
            "        [ 262,    6,    0,    7, 3338,    9,   18,   47,   14,    7,  462,  150,\n",
            "           39,    6,   31,    6,   13,    6,   12,  252,  281,   74,   56,  469,\n",
            "           38, 1476,  192,  879,   17,   12,    5,   55],\n",
            "        [   7, 3009,  612,    6,  900,   17,   65,    6,    0,  160,  700,  680,\n",
            "          132,  257,   11,  175,   68,   87,   24,    7,   55,   58,    6,    7,\n",
            "            0,    9,    7,    5,  650,   24, 3431,    0],\n",
            "        [  50,  210,   11,  112,   23,  816,   10,  713,   60,   10,    6,  180,\n",
            "         2892,   79,   77,   40,    5,   62,  142, 7138,  639,  919, 2879,    6,\n",
            "           11,  971,  940,   66,  266,  122,  164,    4],\n",
            "        [   9,   83,   14, 4487,    5,   38,    8,   10,   11,   14,    0,  228,\n",
            "            0,   38,   87,   60,  148,    8,  664,    7,   12, 1020,  254, 7494,\n",
            "          463,    0,   40,   87,   54,    4,    4,    3],\n",
            "        [  82,   11,  165,   11,   13,    9,   16,   54,    6,   89,   25,    7,\n",
            "            7, 4315,   27,   12,   22,   34,   38,    6,   77, 1800,  235,   12,\n",
            "          896,  140,    4,    4,    4,    3,    3,    1],\n",
            "        [  10,    6,    7,   15,    7,   11,   53,    9,   78,   83,   11,    6,\n",
            "            6,   21,   24,    6,    6,  154,  788,    0,  259,    4,    4,    4,\n",
            "            4,    4,    3,    3,    3,    1,    1,    1],\n",
            "        [  10, 5079,  173,  514,    6,   14,   59,   17,  300,    8,   14,  155,\n",
            "         1419,  922,    0,  567, 4107,    4,    4,    4,    4,    3,    3,    3,\n",
            "            3,    3,    1,    1,    1,    1,    1,    1],\n",
            "        [  51,    8,    9,  208, 2202,   46,    6,   12,   33,   34,    0,    8,\n",
            "          303,    4,    4,    4,    4,    3,    3,    3,    3,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [ 534, 2209,   17,    0,   56, 4984,  754,   15,  142,   72,   21, 1386,\n",
            "            4,    3,    3,    3,    3,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  10,  119,   51, 5884,    9,   20,  266,   34,   72,    4,    4,    4,\n",
            "            3,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  11,   10, 2151,    0,   35,   86, 4599,  157,    4,    3,    3,    3,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  82,   20,   61,  233,    5,    4,    4,    4,    3,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [5143,   86,    9,   12,  244,    3,    3,    3,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  12,   29,    7,   15,   13,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  15,   17,   15,  311,  681,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  34, 2963,  481,    4,    4,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [   9,    4,    4,    3,    3,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  20,    3,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  86,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  84,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [ 768,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  10,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [3828,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  28,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [ 144,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [   4,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [   3,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1]], device='cuda:0') torch.Size([31, 32])\n",
            "tensor([[   2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
            "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
            "            2,    2,    2,    2,    2,    2,    2,    2],\n",
            "        [ 106,    4,    4,    4,    6,    4,   16,    4,    4,    4,   24,    4,\n",
            "            4,    4,    4,    4,    4,   33,   21,    4,    4,   16,    9,   48,\n",
            "           21,    7,    4,   16,    6,   16,    4,   16],\n",
            "        [  19,    9, 3588,    9,   43,  122,   30,    9,    9,   24,    9,    9,\n",
            "           55,   55,   53,    9,    9,    8,  145,   59, 2228,   26,   92,   24,\n",
            "          115,   33,    9,   53, 5177,  104,  153,   19],\n",
            "        [  17,    6, 5705,  465,   12,   14,   15,   10,    6,    9,  489,    6,\n",
            "          410,    6,   34,    6,   73,    4,    9,  448,    9,  666,   75,   34,\n",
            "          975,   10,   13,  127,   15,   32,   10,   79],\n",
            "        [ 239,    4, 4119,    4,   21,   37,   16,   49,    4,   22,  111,   25,\n",
            "           66,    4,   11,   21,    6,  157,  137,   12,   10,   41,   12, 2419,\n",
            "          962, 3767,  217,   17,    7,    8,  883,    8],\n",
            "        [   6,  978,  177,   70,  106,  213,   63,    4,  728,  175,   49,  148,\n",
            "          530,  194,   27,   86,   31,  328,   21,   19,  375,    6,    4,    6,\n",
            "            8,  163,    6,  714,  622,  185,   11,    7],\n",
            "        [   7,  193,   13,  261,  275,   15,   15,  332,  614,   11,  186,   10,\n",
            "         5614,   23,   99,   23,  296,   40,  774,   17,    8,  548, 2021,    4,\n",
            "            4,   15,    4,    4,   17,    3,  290,  514],\n",
            "        [  39,   10,    4,  471,  207,    6,   11,  271,   81,   81,    4,    6,\n",
            "            6,    0,  150,   41,    4,    4,    8,   36,   27, 1105,   69,  128,\n",
            "           46,  263,   90,   53,  298,    1,   10,   12],\n",
            "        [  13,   41,  120,  100,   46,   43,    4,   13,  125,   41,  836,    4,\n",
            "            4,  137,   57,    8,  134,   39,    7,    6,  295,  101,    7,    5,\n",
            "           42, 5703,   23,   99,   12,    1,   45,    4],\n",
            "        [ 250,   51,    6,  114,    9,   12,   14,   19,    7,   40,  838,  118,\n",
            "          670,  746,    7,    4,   12,    5,   84, 1434,    8,    5,  225,    3,\n",
            "            9,    5,    5,    5,   19,    1,  143,   88],\n",
            "        [  11,    4,   26,  706, 1291,    4,  255,   41,   84,    4,   54,  411,\n",
            "            5,   74,    0,  288,    4,    3,    5,   20,    7,    3,    5,    1,\n",
            "          200,    3,    3,    3,    5,    1,    5,    3],\n",
            "        [ 470,  333,   13,  160,    6,   29,   32,    8,  151,   39, 5726,    4,\n",
            "            3,   47, 1496,    5, 1300,    1,    3,    4,  156,    1,    3,    1,\n",
            "           13,    1,    1,    1,    3,    1,    3,    1],\n",
            "        [   6,  966,   25,    0,    4, 1532,   40,    7,    4,    5,   33,  409,\n",
            "            1, 2304,    5,    3,  358,    1,    1, 1192,   12,    1,    1,    1,\n",
            "          522,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [   7,   13, 2020,    0,  243,   98,   80,   39,   59,    3,    5,    5,\n",
            "            1,    5,    3,    1,    5,    1,    1,  131,    7,    1,    1,    1,\n",
            "          423,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  98,    4,    6,    0,   28,    5,    4,    5,  343,    1,    3,    3,\n",
            "            1,    3,    1,    1,    3,    1,    1,  235,  142,    1,    1,    1,\n",
            "            5,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  15,  978,    7,  160,   82,    3,  100,    3,    5,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    5,    5,    1,    1,    1,\n",
            "            3,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  28, 3998,  452,    8,    9,    1,  473,    1,    3,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    3,    3,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  22,  265,    5,    7, 1265,    1,   13,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  31,   13,    3,  156,    5,    1, 2361,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  15,  362,    1,    5,    3,    1,    5,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  25,    6,    1,    3,    1,    1,    3,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  15,    7,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  11,   98,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  52,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [ 306,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [ 567,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  13,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [  52,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [3456,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [   5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [   3,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1]], device='cuda:0') torch.Size([31, 32])\n",
            "##### EXAMPLE #####\n",
            "SRC:  <sos> ein mann in einem schweren mantel läuft mit einem seesack eine steintreppe hoch und im hintergrund steht die polizei . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "TRG:  <sos> a man in a heavy coat is walking up a stone staircase with a heavy duffel bag with police in the background . <eos> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "SRC vocab size 7866\n",
            "TRG vocab size 5898\n",
            "Vocab [('<unk>', 0), ('<pad>', 1), ('<sos>', 2), ('<eos>', 3), ('.', 4), ('ein', 5), ('einem', 6), ('in', 7), ('eine', 8), (',', 9)]\n"
          ]
        }
      ],
      "source": [
        "pad_id_trg = TRG.vocab.stoi[TRG.pad_token]\n",
        "pad_id_src = SRC.vocab.stoi[SRC.pad_token]\n",
        "pad_id = pad_id_src\n",
        "eos_id = TRG.vocab.stoi[TRG.eos_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_id)\n",
        "\n",
        "for batch in train_iter:\n",
        "    src, trg, length_src = sort_batch(batch.src, batch.trg)\n",
        "    print(length_src)\n",
        "    print(src, src.shape)\n",
        "    print(trg, trg.shape)\n",
        "    break\n",
        "\n",
        "print(\"##### EXAMPLE #####\")\n",
        "print(\"SRC: \", word_ids_to_sentence(src[:, 1:2].long().cpu(), SRC.vocab))\n",
        "print(\"TRG: \", word_ids_to_sentence(trg[:, 1:2].long().cpu(), TRG.vocab))\n",
        "\n",
        "print(\"SRC vocab size\", len(SRC.vocab.stoi))\n",
        "print(\"TRG vocab size\", len(TRG.vocab.stoi))\n",
        "print(\"Vocab\", list(SRC.vocab.stoi.items())[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YK28D7EO_Fd"
      },
      "source": [
        "### LSTMCell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "AT0CJePPPS_E"
      },
      "outputs": [],
      "source": [
        "class LSTMCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(LSTMCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.linear_input = nn.Linear(input_size, 4 * hidden_size)\n",
        "        self.linear_hidden = nn.Linear(hidden_size, 4 * hidden_size)\n",
        "\n",
        "    def forward(self, x, state):\n",
        "        hx = state[0]\n",
        "        cx = state[1]\n",
        "        hx1 = self.linear_hidden(hx)\n",
        "        x1 = self.linear_input(x)\n",
        "        sum = x1 + hx1\n",
        "\n",
        "        chunks = torch.chunk(sum, chunks=4, dim=1)\n",
        "        chunk_forgetgate = chunks[0]\n",
        "        chunk_ingate = chunks[1]\n",
        "        chunk_cellgate = chunks[2]\n",
        "        chunk_outgate = chunks[3]\n",
        "\n",
        "        fx = torch.sigmoid(chunk_forgetgate)\n",
        "        ix = torch.sigmoid(chunk_ingate)\n",
        "        anormalcy = torch.tanh(chunk_cellgate)\n",
        "        ox = torch.sigmoid(chunk_outgate)\n",
        "\n",
        "        hasil = fx * cx\n",
        "        another_hasil = ix*anormalcy\n",
        "        another_sum = hasil + another_hasil\n",
        "\n",
        "        cy = another_sum\n",
        "\n",
        "        hy = ox * torch.tanh(another_sum)\n",
        "\n",
        "        state = hy, (hy, cy)\n",
        "        return state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOd-XpyGO_qH"
      },
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "Wjf1QmRAPYdd"
      },
      "outputs": [],
      "source": [
        "class LSTMLayer(nn.Module):\n",
        "    def __init__(self, *cell_args):\n",
        "        super(LSTMLayer, self).__init__()\n",
        "        self.cell = LSTMCell(*cell_args)\n",
        "\n",
        "    def forward(self, x, state, length_x=None):\n",
        "        inputs = x.unbind(0)\n",
        "        # Ensure the sequence lengths are sorted in descending order, if provided\n",
        "        assert (length_x is None) or torch.all(length_x == length_x.sort(descending=True)[0])\n",
        "        \n",
        "        outputs = []\n",
        "        out_hidden_state = []\n",
        "        out_cell_state = []\n",
        "        for i in range(len(inputs)):\n",
        "            # Process each time step using LSTMCell\n",
        "            out, state = self.cell(inputs[i], state)\n",
        "            outputs += [out]\n",
        "            \n",
        "            if length_x is not None:\n",
        "                if torch.any(i + 1 == length_x):\n",
        "                    out_hidden_state = [state[0][i + 1 == length_x]] + out_hidden_state\n",
        "                    out_cell_state = [state[1][i + 1 == length_x]] + out_cell_state\n",
        "        \n",
        "        # If sequence lengths are provided, concatenate the hidden and cell states\n",
        "        if length_x is not None:\n",
        "            state = (torch.cat(out_hidden_state, dim=0), torch.cat(out_cell_state, dim=0))\n",
        "        \n",
        "        return torch.stack(outputs), state\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, ninp, nhid, num_layers, dropout):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.layers = []\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        # Stack multiple LSTM layers\n",
        "        for i in range(num_layers):\n",
        "            if i == 0:\n",
        "                self.layers.append(LSTMLayer(ninp, nhid))\n",
        "            else:\n",
        "                self.layers.append(LSTMLayer(nhid, nhid))\n",
        "        self.layers = nn.ModuleList(self.layers)\n",
        "\n",
        "    def forward(self, x, states, length_x=None):\n",
        "        output_states = []\n",
        "        length = len(states)\n",
        "        \n",
        "        # Pass the input through each LSTM layer\n",
        "        for i in range(length):\n",
        "            x, output_state = self.layers[i](x, states[i], length_x=length_x)\n",
        "            if i != length - 1:\n",
        "                x = self.dropout(x)  # Apply dropout after each layer except the last\n",
        "            output_states.append(output_state)\n",
        "        \n",
        "        return x, output_states"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXJsTGg3O-m4"
      },
      "source": [
        "### LSTMEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "1b6J1a39PY4P"
      },
      "outputs": [],
      "source": [
        "class LSTMEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTMEncoder, self).__init__()\n",
        "        ninp = args.ninp\n",
        "        nhid = args.nhid\n",
        "        nlayers = args.nlayers\n",
        "        dropout = args.dropout\n",
        "        self.embed = nn.Embedding(src_ntoken, ninp, padding_idx=pad_id)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.lstm = LSTM(ninp, nhid, nlayers, dropout)\n",
        "\n",
        "    def forward(self, x, states, length_x=None):\n",
        "        embedded = self.embed(x)\n",
        "        embedded = self.dropout(embedded)\n",
        "        output, context_vector = self.lstm(embedded, states, length_x)\n",
        "        return output, context_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrFAmuJRO9eG"
      },
      "source": [
        "### LSTMDecoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "k2vRxaa3PZom"
      },
      "outputs": [],
      "source": [
        "class LSTMDecoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTMDecoder, self).__init__()\n",
        "        self.embed = nn.Embedding(trg_ntoken, args.ninp, padding_idx=pad_id)\n",
        "        self.lstm = LSTM(args.ninp, args.nhid, args.nlayers, args.dropout)\n",
        "        self.fc_out = nn.Linear(args.nhid, trg_ntoken)\n",
        "        self.dropout = nn.Dropout(args.dropout)\n",
        "        self.fc_out.weight = self.embed.weight\n",
        "\n",
        "    def forward(self, x, states):\n",
        "        embedded = self.embed(x)\n",
        "        embedded = self.dropout(embedded)\n",
        "        output, output_states = self.lstm(embedded, states)\n",
        "        output = self.fc_out(output)\n",
        "        return output, output_states"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjbbVJcbO9I3"
      },
      "source": [
        "### LSTMSeq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "NLC1mpEFm05u"
      },
      "outputs": [],
      "source": [
        "class LSTMSeq2Seq(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTMSeq2Seq, self).__init__()\n",
        "        self.encoder = LSTMEncoder()\n",
        "        self.decoder = LSTMDecoder()\n",
        "\n",
        "    def _get_init_states(self, x):\n",
        "        init_states = [\n",
        "            (torch.zeros((x.size(1), args.nhid)).to(x.device),\n",
        "            torch.zeros((x.size(1), args.nhid)).to(x.device))\n",
        "            for _ in range(args.nlayers)\n",
        "        ]\n",
        "        return init_states\n",
        "\n",
        "    def forward(self, x, y, length, max_len=None, teacher_forcing=True):\n",
        "        init_states = self._get_init_states(x)\n",
        "        output, output_states = self.encoder(x, init_states, length)\n",
        "        decoder_input = y[0:1]\n",
        "\n",
        "        decoder_states = output_states\n",
        "        decoder_outputs = []\n",
        "        \n",
        "        if max_len == None:\n",
        "          trg_len = y.size(0)\n",
        "        else:\n",
        "          trg_len = max_len\n",
        "\n",
        "        output, decoder_states = self.decoder(decoder_input, decoder_states)\n",
        "        decoder_outputs.append(output)\n",
        "        for i in range(1, trg_len-1):\n",
        "            if teacher_forcing:\n",
        "                decoder_input = y[i:i+1]\n",
        "            else:\n",
        "                decoder_input = output.argmax(dim=-1)\n",
        "            output, decoder_states = self.decoder(decoder_input, decoder_states)\n",
        "            decoder_outputs.append(output)\n",
        "        decoder_outputs = torch.cat(decoder_outputs)\n",
        "        return decoder_outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wbnEENVFXuy"
      },
      "source": [
        "### Attention\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUDUEcWwrYyk"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.nhid_enc = args.nhid\n",
        "        self.nhid_dec = args.nhid\n",
        "        self.W1 = nn.Linear(self.nhid_enc, args.nhid_attn)\n",
        "        self.W2 = nn.Linear(self.nhid_dec, args.nhid_attn)\n",
        "        self.W3 = nn.Linear(args.nhid_attn, 1)\n",
        "\n",
        "    def forward(self, x, enc_o, dec_h, length_enc=None):\n",
        "        enc_w = self.W1(enc_o)\n",
        "        dec_h = dec_h.unsqueeze(dim=0)\n",
        "        dec_w = self.W2(dec_h)\n",
        "\n",
        "        combined = torch.tanh(enc_w + dec_w)\n",
        "        attn_scores = self.W3(combined)\n",
        "\n",
        "        if length_enc is not None:\n",
        "            attn_mask = torch.arange(attn_scores.size(0), device=device).unsqueeze(1) >= length_enc.unsqueeze(0)\n",
        "            attn_scores = attn_scores.masked_fill(attn_mask.unsqueeze(-1), float('-inf'))\n",
        "            \n",
        "        attn_weights = F.softmax(attn_scores, dim=0)\n",
        "        attn_applied = torch.sum(enc_o * attn_weights, dim=0, keepdims=True)\n",
        "        output = torch.cat((x, attn_applied), dim=-1)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqdGZ8JMrVQ_"
      },
      "source": [
        "### LSTMAttnDecoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsWZTFDMrexf"
      },
      "outputs": [],
      "source": [
        "class LSTMAttnDecoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTMAttnDecoder, self).__init__()\n",
        "        self.embed = nn.Embedding(trg_ntoken, args.ninp, padding_idx=pad_id)\n",
        "        self.lstm = LSTM(args.ninp + args.nhid, args.nhid, args.nlayers, args.dropout)\n",
        "        self.fc_out = nn.Linear(args.nhid, trg_ntoken)\n",
        "        self.dropout = nn.Dropout(args.dropout)\n",
        "        self.attn = Attention()\n",
        "        self.fc_out.weight = self.embed.weight\n",
        "\n",
        "    def forward(self, x, enc_o, states, length_enc=None):\n",
        "        embedded_x = self.embed(x)\n",
        "        dropout_x = self.dropout(embedded_x)\n",
        "        attn_x = self.attn(dropout_x, enc_o, states[-1][0], length_enc)\n",
        "        last_x, output_states = self.lstm(attn_x, states)\n",
        "        fc_out_x = self.fc_out(last_x)\n",
        "        return fc_out_x, output_states"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7tmYYFPrWp3"
      },
      "source": [
        "### LSTMAttnSeq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R3nNAfJywMf"
      },
      "outputs": [],
      "source": [
        "class LSTMAttnSeq2Seq(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTMAttnSeq2Seq, self).__init__()\n",
        "        self.encoder = LSTMEncoder()\n",
        "        self.decoder = LSTMAttnDecoder()\n",
        "\n",
        "    def _get_init_states(self, x):\n",
        "        init_states = [\n",
        "            (torch.zeros((x.size(1), args.nhid)).to(x.device),\n",
        "            torch.zeros((x.size(1), args.nhid)).to(x.device))\n",
        "            for _ in range(args.nlayers)\n",
        "        ]\n",
        "        return init_states\n",
        "\n",
        "    def forward(self, x, y, length, max_len=None, teacher_forcing=True):\n",
        "        init_states = self._get_init_states(x)\n",
        "        enc_output, enc_states = self.encoder(x, init_states, length)\n",
        "        decoder_input = y[0:1]\n",
        "        decoder_states = init_states\n",
        "        decoder_outputs = []\n",
        "\n",
        "        if max_len == None:\n",
        "          trg_len = y.size(0)\n",
        "        else:\n",
        "          trg_len = max_len\n",
        "\n",
        "        for i in range(trg_len-1):\n",
        "            if teacher_forcing or i == 0:\n",
        "              decoder_input = y[i:i+1]\n",
        "            else:\n",
        "              decoder_input = decoder_output.argmax(-1)\n",
        "            decoder_output, decoder_states = self.decoder(decoder_input, enc_output, decoder_states, length)\n",
        "            decoder_outputs.append(decoder_output)\n",
        "        decoder_outputs = torch.cat(decoder_outputs)\n",
        "        return decoder_outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4tGUyntXKXk"
      },
      "source": [
        "### MaskedMultiheadAttention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "OFeZAJNCPEll"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 100\n",
        "\n",
        "class MaskedMultiheadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Vanilla multi-head attention with an optional causal mask.\n",
        "    It includes key, query, value projections, dropout, and output projection.\n",
        "    \"\"\"\n",
        "    def __init__(self, mask=False):\n",
        "        super(MaskedMultiheadAttention, self).__init__()\n",
        "        assert args.nhid_tran % args.nhead == 0  # Ensure hidden dimension is divisible by number of heads\n",
        "        \n",
        "        # Key, query, value projections for all heads\n",
        "        self.key = nn.Linear(args.nhid_tran, args.nhid_tran)\n",
        "        self.query = nn.Linear(args.nhid_tran, args.nhid_tran)\n",
        "        self.value = nn.Linear(args.nhid_tran, args.nhid_tran)\n",
        "\n",
        "        self.attn_drop = nn.Dropout(args.attn_pdrop)\n",
        "        self.proj = nn.Linear(args.nhid_tran, args.nhid_tran)\n",
        "        \n",
        "        if mask:\n",
        "            self.register_buffer(\"mask\", torch.tril(torch.ones(MAX_LEN, MAX_LEN)))\n",
        "\n",
        "        self.nhead = args.nhead\n",
        "        self.d_k = args.nhid_tran // args.nhead\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        nhead = self.nhead\n",
        "        d_k = self.d_k\n",
        "\n",
        "        # Project the input queries, keys, and values\n",
        "        linear_q = self.query(q)\n",
        "        B, T_q, hidden_size = linear_q.size()\n",
        "        reshaped_q = linear_q.view(B, T_q, nhead, d_k)\n",
        "        transposed_q = reshaped_q.permute(0, 2, 1, 3)\n",
        "\n",
        "        linear_k = self.key(k)\n",
        "        B, T, hidden_size = linear_k.size()\n",
        "        reshaped_k = linear_k.view(B, T, nhead, d_k)\n",
        "        transposed_k = reshaped_k.permute(0, 2, 1, 3)\n",
        "\n",
        "        linear_v = self.value(v)\n",
        "        B, T, hidden_size = linear_v.size()\n",
        "        reshaped_v = linear_v.view(B, T, nhead, d_k)\n",
        "        transposed_v = reshaped_v.permute(0, 2, 1, 3)\n",
        "\n",
        "        att_scores = torch.matmul(transposed_q, transposed_k.transpose(-2, -1))\n",
        "        scaled_att_scores = att_scores / math.sqrt(d_k)\n",
        "\n",
        "        if mask is not None:\n",
        "            scaled_att_scores = scaled_att_scores.masked_fill(mask.unsqueeze(1).unsqueeze(2) == 0, float('-inf'))\n",
        "\n",
        "        if hasattr(self, 'mask'):\n",
        "            T_q, T = q.size(1), k.size(1)\n",
        "            scaled_att_scores = scaled_att_scores.masked_fill(self.mask[:T_q, :T].unsqueeze(0).unsqueeze(0) == 0, float('-inf'))\n",
        "\n",
        "        # Compute attention weights and apply dropout\n",
        "        att_weights = F.softmax(scaled_att_scores, dim=-1)\n",
        "        att_dropout = self.attn_drop(att_weights)\n",
        "        last_mul = torch.matmul(att_dropout, transposed_v)\n",
        "        trasposed_mask = last_mul.permute(0, 2, 1, 3)\n",
        "\n",
        "        B, T_q, nhead, d_k = trasposed_mask.size()\n",
        "        reshaped_mask = trasposed_mask.reshape(B, T_q, nhead * d_k)\n",
        "        y = self.proj(reshaped_mask)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWn3GenhPG1G"
      },
      "source": [
        "\n",
        "### TransformerEncLayer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "1RcLE8QKPPfJ"
      },
      "outputs": [],
      "source": [
        "class TransformerEncLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TransformerEncLayer, self).__init__()\n",
        "        self.ln1 = nn.LayerNorm(args.nhid_tran)\n",
        "        self.ln2 = nn.LayerNorm(args.nhid_tran)\n",
        "        self.attn = MaskedMultiheadAttention()\n",
        "        self.dropout1 = nn.Dropout(args.resid_pdrop)\n",
        "        self.dropout2 = nn.Dropout(args.resid_pdrop)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(args.nhid_tran, args.nff),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(args.nff, args.nhid_tran)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        norm_x = self.ln1(x)\n",
        "        att = self.attn(norm_x, norm_x, norm_x, mask)\n",
        "        drop_att = self.dropout1(att)\n",
        "        res_con = norm_x + drop_att\n",
        "        norm_2 = self.ln2(res_con)\n",
        "        forward = self.ff(norm_2)\n",
        "        drop_2 = self.dropout2(forward)\n",
        "        outputs = norm_2 + drop_2\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKz8TOrEPVu4"
      },
      "source": [
        "### TransformerDecLayer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "Bnp9dhwsPXjB"
      },
      "outputs": [],
      "source": [
        "class TransformerDecLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TransformerDecLayer, self).__init__()\n",
        "        self.ln1 = nn.LayerNorm(args.nhid_tran)\n",
        "        self.ln2 = nn.LayerNorm(args.nhid_tran)\n",
        "        self.ln3 = nn.LayerNorm(args.nhid_tran)\n",
        "        self.dropout1 = nn.Dropout(args.resid_pdrop)\n",
        "        self.dropout2 = nn.Dropout(args.resid_pdrop)\n",
        "        self.dropout3 = nn.Dropout(args.resid_pdrop)\n",
        "        self.attn1 = MaskedMultiheadAttention(mask=True) # self-attention\n",
        "        self.attn2 = MaskedMultiheadAttention() # tgt to src attention\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(args.nhid_tran, args.nff),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(args.nff, args.nhid_tran)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, enc_o, enc_mask=None):\n",
        "        norm_x = self.ln1(x)\n",
        "        att = self.attn1(norm_x, norm_x, norm_x)\n",
        "        drop_att = self.dropout1(att)\n",
        "        res_con = norm_x + drop_att\n",
        "        norm_2 = self.ln2(res_con)\n",
        "        att2 = self.attn2(norm_2, enc_o, enc_o, mask=enc_mask)\n",
        "        drop_att_2 = self.dropout2(att2)\n",
        "        res_con_2 = norm_2 + drop_att_2\n",
        "        norm_3 = self.ln3(res_con_2)\n",
        "        forward = self.ff(norm_3)\n",
        "        drop_att_3 = self.dropout3(forward)\n",
        "        outputs = drop_att_3 + norm_3\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NO7tjDWvPbx3"
      },
      "source": [
        "### TransformerEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "EjdoK0opPdEC"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, max_len=4096):\n",
        "        super().__init__()\n",
        "        dim = args.nhid_tran\n",
        "        pos = np.arange(0, max_len)[:, None]\n",
        "        i = np.arange(0, dim // 2)\n",
        "        denom = 10000 ** (2 * i / dim)\n",
        "\n",
        "        pe = np.zeros([max_len, dim])\n",
        "        pe[:, 0::2] = np.sin(pos / denom)\n",
        "        pe[:, 1::2] = np.cos(pos / denom)\n",
        "        pe = torch.from_numpy(pe).float()\n",
        "\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:x.shape[1]]\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        # input embedding stem\n",
        "        self.tok_emb = nn.Embedding(src_ntoken, args.nhid_tran)\n",
        "        self.pos_enc = PositionalEncoding()\n",
        "        self.dropout = nn.Dropout(args.embd_pdrop)\n",
        "        # transformer\n",
        "        self.transform = nn.ModuleList([TransformerEncLayer() for _ in range(args.nlayers_transformer)])\n",
        "        # decoder head\n",
        "        self.ln_f = nn.LayerNorm(args.nhid_tran)\n",
        "\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x_embd = self.tok_emb(x)\n",
        "        x_pos = self.pos_enc(x_embd)\n",
        "        x_drop = self.dropout(x_pos)\n",
        "        for layer in self.transform:\n",
        "            x_drop = layer(x_drop, mask)\n",
        "        outputs = self.ln_f(x_drop)\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkSdxiGJPgPm"
      },
      "source": [
        "### TransformerDecoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "Ft64IQHrPlCb"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "        self.tok_emb = nn.Embedding(trg_ntoken, args.nhid_tran)\n",
        "        self.pos_enc = PositionalEncoding()\n",
        "        self.dropout = nn.Dropout(args.embd_pdrop)\n",
        "        self.transform = nn.ModuleList([TransformerDecLayer() for _ in range(args.nlayers_transformer)])\n",
        "        self.ln_f = nn.LayerNorm(args.nhid_tran)\n",
        "        self.lin_out = nn.Linear(args.nhid_tran, trg_ntoken)\n",
        "        self.lin_out.weight = self.tok_emb.weight\n",
        "\n",
        "\n",
        "    def forward(self, x, enc_o, enc_mask):\n",
        "        x_embd = self.tok_emb(x)\n",
        "        x_pos = self.pos_enc(x_embd)\n",
        "        x_drop = self.dropout(x_pos)\n",
        "        for layer in self.transform:\n",
        "            x_drop = layer(x_drop, enc_o, enc_mask)\n",
        "        result = self.ln_f(x_drop)\n",
        "        outputs = self.lin_out(result)\n",
        "        logits = outputs\n",
        "        logits /= args.nhid_tran ** 0.5 # Scaling logits\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nxKg_RfPpz4"
      },
      "source": [
        "### Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "EWsZrYEGywMi"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = TransformerEncoder()\n",
        "        self.decoder = TransformerDecoder()\n",
        "\n",
        "    def forward(self, x, y, length_x, max_len=None, teacher_forcing=True):\n",
        "        B, T = x.size()\n",
        "\n",
        "        enc_mask = torch.arange(T, device=x.device).unsqueeze(0) < length_x.unsqueeze(1)\n",
        "        enc_o = self.encoder(x, enc_mask)\n",
        "\n",
        "        if teacher_forcing or self.training:\n",
        "            outputs = self.decoder(y[:, :-1], enc_o, enc_mask)\n",
        "            return outputs\n",
        "        else:\n",
        "            dec_input = y[:, :1]\n",
        "            outputs = []\n",
        "            for i in range(max_len - 1):\n",
        "                dec_output = self.decoder(dec_input, enc_o, enc_mask)\n",
        "\n",
        "                dec_input = torch.cat((dec_input, dec_output[:, -1:].argmax(-1)), dim=1)\n",
        "        return dec_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHQzs6ocPxtQ"
      },
      "source": [
        "### Run Experiment\n",
        "\n",
        "After implementing models, you can run the experiment. \n",
        "Make sure to execute all prior cells to ensure the functions are properly initialized. \n",
        "Training a model for 20 epochs is expected to take less than an hour."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdxUX81cywMk"
      },
      "outputs": [],
      "source": [
        "def run_experiment(model):\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=pad_id)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args.lr_lstm if not isinstance(model, Transformer) else args.lr_transformer)\n",
        "\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
        "            factor=0.25, patience=1, threshold=0.0001, threshold_mode='rel',\n",
        "            cooldown=0, min_lr=0, eps=1e-08, verbose=False)\n",
        "\n",
        "    best_val_loss = np.inf\n",
        "    for epoch in tq.tqdm(range(args.epochs)):\n",
        "        run_epoch(epoch, model, optimizer, is_train=True)\n",
        "        with torch.no_grad():\n",
        "            val_loss = run_epoch(epoch, model, None, is_train=False)\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            save_model(model, 'best')\n",
        "        save_model(model)\n",
        "        scheduler.step(val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UytcJfBv8b3Y"
      },
      "source": [
        "### Evaluation Metrics:\n",
        "I used\n",
        "\n",
        "- PPL (Perplexity)**: Measures how many words the model considers as candidates at each time step. A lower perplexity indicates the model is more confident in its predictions.\n",
        "  \n",
        "- BLEU (Bilingual Evaluation Understudy) Score: A metric for evaluating machine translation output. It takes into account:\n",
        "  - Precision: How accurate each n-gram in the predicted sentence is.\n",
        "  - Clipping: Adjusts the score when a word occurs multiple times in both the true and predicted sentences.\n",
        "  - Brevity penalty: Ensures the predicted and true sentences are of similar length.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "274cd11366564e97b480bb07462460ad",
            "77c5a61b515247479c497fc697a2301c",
            "3584f4fe82f34badafb301303d7859e3",
            "ad8ee31568fe4d7f8ead5c253026c5ca",
            "55e45bfd2dbe4fab82d84841575e563c",
            "1833335cc42f46ec9c578c9213acd985",
            "1bcc69d3bb614c05bd02a48b99c83425",
            "40621c2b9bd44cef988770523680ac14",
            "5a0104b1a9f14445b47460a095760501",
            "58db2ad597c9418b990f6d936fc1b37b",
            "863d10f457834c758e604d141ebec0af"
          ]
        },
        "id": "-ByvNFinywMm",
        "outputId": "42fe948d-881a-49d3-9c4c-187f5b7ad4ce"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "274cd11366564e97b480bb07462460ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 Train Loss 4.312899874679481 Acc 0.30242674552164034 PPL 74.65667032732284\n",
            "Epoch 0 Valid Loss 3.576150340584837 Acc 0.37091412742382274 PPL 35.73570541274967\n",
            "Epoch 1 Train Loss 3.4388460914463868 Acc 0.3964197561035216 PPL 31.150992025328645\n",
            "Epoch 1 Valid Loss 3.1774623445856935 Acc 0.4268005540166205 PPL 23.985808539143218\n",
            "Epoch 2 Train Loss 3.0875502400502084 Acc 0.44260856814682664 PPL 21.92330530228815\n",
            "Epoch 2 Valid Loss 2.914142611102714 Acc 0.4628116343490305 PPL 18.433001374893145\n",
            "Epoch 3 Train Loss 2.824112078335317 Acc 0.47553214887949363 PPL 16.845980432407735\n",
            "Epoch 3 Valid Loss 2.7203485062082717 Acc 0.49265927977839336 PPL 15.18561360348192\n",
            "Epoch 4 Train Loss 2.594577103635457 Acc 0.5047044160414478 PPL 13.390923191078356\n",
            "Epoch 4 Valid Loss 2.554895649260101 Acc 0.5165512465373961 PPL 12.869956597955268\n",
            "Epoch 5 Train Loss 2.3991003472663612 Acc 0.5293628876561011 PPL 11.013263809481828\n",
            "Epoch 5 Valid Loss 2.4421737390046636 Acc 0.532202216066482 PPL 11.49800726447968\n",
            "Epoch 6 Train Loss 2.2319546928095555 Acc 0.5514504264522594 PPL 9.318062238996369\n",
            "Epoch 6 Valid Loss 2.3610828102047754 Acc 0.5473684210526316 PPL 10.602425653814826\n",
            "Epoch 7 Train Loss 2.0874011308474083 Acc 0.5701532295510643 PPL 8.063930807293195\n",
            "Epoch 7 Valid Loss 2.292289001434794 Acc 0.5600415512465374 PPL 9.897567317448123\n",
            "Epoch 8 Train Loss 1.9615569278887341 Acc 0.5867494318042963 PPL 7.110388814394067\n",
            "Epoch 8 Valid Loss 2.2447753071454755 Acc 0.5674515235457064 PPL 9.438294600831785\n",
            "Epoch 9 Train Loss 1.8474905430007684 Acc 0.6021921356826901 PPL 6.343879837329221\n",
            "Epoch 9 Valid Loss 2.214664295472597 Acc 0.574376731301939 PPL 9.158334101268972\n",
            "Epoch 10 Train Loss 1.7477182161254778 Acc 0.6162027420024927 PPL 5.741486885805283\n",
            "Epoch 10 Valid Loss 2.197288544802124 Acc 0.5775623268698061 PPL 9.0005757256068\n",
            "Epoch 11 Train Loss 1.6554406093520944 Acc 0.6293017913438745 PPL 5.235386174172825\n",
            "Epoch 11 Valid Loss 2.1808246746618 Acc 0.5808171745152355 PPL 8.853604592304738\n",
            "Epoch 12 Train Loss 1.5727846981295188 Acc 0.641203352965615 PPL 4.820051912002535\n",
            "Epoch 12 Valid Loss 2.1622128951582553 Acc 0.5851108033240997 PPL 8.690347223542261\n",
            "Epoch 13 Train Loss 1.4956264251316016 Acc 0.6539895891883966 PPL 4.4621308684581855\n",
            "Epoch 13 Valid Loss 2.162307027576703 Acc 0.5833795013850416 PPL 8.691165305446972\n",
            "Epoch 14 Train Loss 1.4242048332251227 Acc 0.6657298565458589 PPL 4.154552966482825\n",
            "Epoch 14 Valid Loss 2.17348518018247 Acc 0.5837257617728532 PPL 8.788861491724473\n",
            "Epoch 15 Train Loss 1.2681661900472931 Acc 0.6964417507759232 PPL 3.5543286191507995\n",
            "Epoch 15 Valid Loss 2.147431816998611 Acc 0.5870498614958449 PPL 8.562839196543736\n",
            "Epoch 16 Train Loss 1.2210845590794337 Acc 0.7068574500843129 PPL 3.3908633316729087\n",
            "Epoch 16 Valid Loss 2.1477853985952207 Acc 0.5909279778393352 PPL 8.565867394224297\n",
            "Epoch 17 Train Loss 1.1934445562349911 Acc 0.7127495784354456 PPL 3.2984232664165845\n",
            "Epoch 17 Valid Loss 2.1547516724326936 Acc 0.5907894736842105 PPL 8.625747901993845\n",
            "Epoch 18 Train Loss 1.1460478007111714 Acc 0.7229233363474181 PPL 3.1457357347520327\n",
            "Epoch 18 Valid Loss 2.1531250394199692 Acc 0.5907894736842105 PPL 8.611728381096011\n",
            "Epoch 19 Train Loss 1.1357203604803923 Acc 0.7251643490798896 PPL 3.11341551679082\n",
            "Epoch 19 Valid Loss 2.153606907069848 Acc 0.5890581717451524 PPL 8.615879094379316\n",
            "--------- Translation Example 1 ---------\n",
            "SRC : ein reh springt über einen zaun .\n",
            "TRG : a deer jumps a fence .\n",
            "PRED: a parent is jumping over a fence .\n",
            "--------- Translation Example 2 ---------\n",
            "SRC : ein radfahrer springt über eine hindernis .\n",
            "TRG : a biker jumps an obstacle .\n",
            "PRED: a bicyclist is jumping over a hurdle .\n",
            "--------- Translation Example 3 ---------\n",
            "SRC : zwei kleine kinder auf dem sand .\n",
            "TRG : two young children are on sand .\n",
            "PRED: two young children are on sand .\n",
            "--------- Translation Example 4 ---------\n",
            "SRC : ein kleiner schwarzer hund springt über <unk>\n",
            "TRG : a small black dog jumping over gates\n",
            "PRED: a small black dog jumps over some <unk> .\n",
            "--------- Translation Example 5 ---------\n",
            "SRC : ein mann schneidet äste von bäumen .\n",
            "TRG : a man cutting branches of trees .\n",
            "PRED: a man is cutting up some trees .\n",
            "\n",
            "BLEU: 0.24301552772521973\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lstm_model = LSTMSeq2Seq().to(device)\n",
        "lstm_model.apply(init_weights)\n",
        "run_experiment(lstm_model)\n",
        "run_translation(lstm_model, test_iter, max_len=100)\n",
        "print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2af3e9e7fd804ed18073fcb8bb959ac5",
            "1164a124a5444aafb3caa4836317d2ea",
            "a26d2b5e1f714c5089fbbae79e15bcaa",
            "e8b5dd085d6b4e9986ee2e2cf94e3eae",
            "8fd21c14c9f74f4c8a8057726cabfcef",
            "7e7c946fbd18493f9f1308088a10e396",
            "ce3935ea4ba24303992213725d83d3bb",
            "4c3bf16542914dcfbe9bb689b9e6ba49",
            "e8d179b0ac494569b88c837b95058e2b",
            "03507633c11c41479a89b7dca5de76fa",
            "22c6e6a05f5e4db4b8f193d566e0211b"
          ]
        },
        "id": "FRupiwcWCAaO",
        "outputId": "93374b3d-463a-4c38-f323-a695e7c451ea"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2af3e9e7fd804ed18073fcb8bb959ac5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 Train Loss 4.662672258106278 Acc 0.25771646423421884 PPL 105.91874654140688\n",
            "Epoch 0 Valid Loss 3.863868825174765 Acc 0.3340027700831025 PPL 47.64934219984295\n",
            "Epoch 1 Train Loss 3.677890702907214 Acc 0.36343507905862804 PPL 39.56285618290238\n",
            "Epoch 1 Valid Loss 3.338131281180395 Acc 0.40110803324099725 PPL 28.166442333731464\n",
            "Epoch 2 Train Loss 3.23854581367795 Acc 0.4239253158679342 PPL 25.496617942896453\n",
            "Epoch 2 Valid Loss 3.0299028945926816 Acc 0.45013850415512463 PPL 20.695222873767253\n",
            "Epoch 3 Train Loss 2.927964999325048 Acc 0.46587648769520273 PPL 18.689558507372624\n",
            "Epoch 3 Valid Loss 2.760555970272529 Acc 0.4918282548476454 PPL 15.808629633591845\n",
            "Epoch 4 Train Loss 2.6647227285311437 Acc 0.49885138933014006 PPL 14.36396627577079\n",
            "Epoch 4 Valid Loss 2.5594666744863557 Acc 0.5216759002770083 PPL 12.928920153508582\n",
            "Epoch 5 Train Loss 2.4345600269553325 Acc 0.5304088565214203 PPL 11.410797165604082\n",
            "Epoch 5 Valid Loss 2.4011797842143974 Acc 0.5478531855955678 PPL 11.03618902467466\n",
            "Epoch 6 Train Loss 2.237647982730512 Acc 0.5577702289889782 PPL 9.37126397156372\n",
            "Epoch 6 Valid Loss 2.2660190742101696 Acc 0.5717451523545707 PPL 9.640944434525862\n",
            "Epoch 7 Train Loss 2.0742577506628357 Acc 0.5809452821427699 PPL 7.958636973132048\n",
            "Epoch 7 Valid Loss 2.17943955250394 Acc 0.5864958448753462 PPL 8.841349757587862\n",
            "Epoch 8 Train Loss 1.9372938480788904 Acc 0.59950389794472 PPL 6.939944990725644\n",
            "Epoch 8 Valid Loss 2.1031731071564628 Acc 0.5973684210526315 PPL 8.19212319926186\n",
            "Epoch 9 Train Loss 1.8164639138893408 Acc 0.6183117867005548 PPL 6.150072767666619\n",
            "Epoch 9 Valid Loss 2.0475776517407716 Acc 0.6085872576177286 PPL 7.749107316326077\n",
            "Epoch 10 Train Loss 1.7131029021880089 Acc 0.6329064737652436 PPL 5.546143948267147\n",
            "Epoch 10 Valid Loss 2.0120769365094704 Acc 0.6149584487534626 PPL 7.47883429187603\n",
            "Epoch 11 Train Loss 1.6219571250826124 Acc 0.6464649673745693 PPL 5.062989530207001\n",
            "Epoch 11 Valid Loss 1.9875634938891245 Acc 0.6231301939058171 PPL 7.297731116528209\n",
            "Epoch 12 Train Loss 1.5410066144610142 Acc 0.6580366089102861 PPL 4.669288079053695\n",
            "Epoch 12 Valid Loss 1.9509110058608807 Acc 0.6281163434903048 PPL 7.035093673720652\n",
            "Epoch 13 Train Loss 1.470125957466896 Acc 0.6685476184657494 PPL 4.349782994206416\n",
            "Epoch 13 Valid Loss 1.9385348856366573 Acc 0.6289473684210526 PPL 6.948563069681689\n",
            "Epoch 14 Train Loss 1.4077242791470599 Acc 0.6787262640827 PPL 4.086644751187129\n",
            "Epoch 14 Valid Loss 1.9339857482018563 Acc 0.6319252077562327 PPL 6.917024891446224\n",
            "Epoch 15 Train Loss 1.3471234993800154 Acc 0.6888609203548474 PPL 3.846345587138494\n",
            "Epoch 15 Valid Loss 1.9277387811371494 Acc 0.6377423822714682 PPL 6.873949151213225\n",
            "Epoch 16 Train Loss 1.2928501011131184 Acc 0.698233094650407 PPL 3.6431551334878254\n",
            "Epoch 16 Valid Loss 1.9295925085812065 Acc 0.6392659279778393 PPL 6.886703397199498\n",
            "Epoch 17 Train Loss 1.2475345731094736 Acc 0.7057210586768983 PPL 3.4817483710929222\n",
            "Epoch 17 Valid Loss 1.9340155717738778 Acc 0.6388504155124654 PPL 6.9172311849124375\n",
            "Epoch 18 Train Loss 1.1082936878508087 Acc 0.7338253623011315 PPL 3.029185246599886\n",
            "Epoch 18 Valid Loss 1.8870326262679458 Acc 0.643005540166205 PPL 6.59975565427794\n",
            "Epoch 19 Train Loss 1.063995273809704 Acc 0.743771841931621 PPL 2.8979258988300876\n",
            "Epoch 19 Valid Loss 1.8867409891286384 Acc 0.6441135734072022 PPL 6.597831201053455\n",
            "--------- Translation Example 1 ---------\n",
            "SRC : ein reh springt über einen zaun .\n",
            "TRG : a deer jumps a fence .\n",
            "PRED: a couple jumps over a fence .\n",
            "--------- Translation Example 2 ---------\n",
            "SRC : ein radfahrer springt über eine hindernis .\n",
            "TRG : a biker jumps an obstacle .\n",
            "PRED: a bicyclist is jumping over a hurdle .\n",
            "--------- Translation Example 3 ---------\n",
            "SRC : zwei kleine kinder auf dem sand .\n",
            "TRG : two young children are on sand .\n",
            "PRED: two young children on the sand .\n",
            "--------- Translation Example 4 ---------\n",
            "SRC : ein kleiner schwarzer hund springt über <unk>\n",
            "TRG : a small black dog jumping over gates\n",
            "PRED: a small black dog jumps over hurdles .\n",
            "--------- Translation Example 5 ---------\n",
            "SRC : ein mann schneidet äste von bäumen .\n",
            "TRG : a man cutting branches of trees .\n",
            "PRED: a man is cutting wood <unk> with the trees .\n",
            "\n",
            "BLEU: 0.33470807471053426\n",
            "\n"
          ]
        }
      ],
      "source": [
        "attn_model = LSTMAttnSeq2Seq().to(device)\n",
        "attn_model.apply(init_weights)\n",
        "run_experiment(attn_model)\n",
        "run_translation(attn_model, test_iter, max_len=100)\n",
        "print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ac048b072bba4b319bd08a92ae6d551e",
            "21cfc14cf7f24ade94663d4f8d143a3d",
            "b2dd3ad89b5a469781ef488c49acde84",
            "278683c124f649c4a8d75d71791a85a5",
            "9bf1a18e61e149c1b2156d6541e6eeb8",
            "ffd59f832ea0487a853a8ad27da8659c",
            "2f19fa0757744b51a7a160d68f4fe549",
            "61a04b5bd6ac43b29ce4dd967e8d12fa",
            "52c8b9f7c3a347209fb6078b76012cac",
            "7da1c3a0497149ec981a367b2b7c6083",
            "09cfa44ea74a40a38f99741af62397c6"
          ]
        },
        "id": "UU65AMeUywMu",
        "outputId": "c4a4733a-caf0-4789-f644-25acc8ab9ef2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac048b072bba4b319bd08a92ae6d551e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 Train Loss 4.726734042237 Acc 0.39351401549402476 PPL 112.92614740246252\n",
            "Epoch 0 Valid Loss 3.7225598553871513 Acc 0.49584487534626037 PPL 41.37016030549578\n",
            "Epoch 1 Train Loss 3.5956779093438107 Acc 0.503682885701019 PPL 36.44039490067257\n",
            "Epoch 1 Valid Loss 3.101942064557379 Acc 0.5505540166204986 PPL 22.241103024044055\n",
            "Epoch 2 Train Loss 3.124621266065308 Acc 0.5444316821036682 PPL 22.751276781031496\n",
            "Epoch 2 Valid Loss 2.7900860570804564 Acc 0.5767313019390582 PPL 16.28242095910831\n",
            "Epoch 3 Train Loss 2.8313955043866 Acc 0.5703853955375253 PPL 16.96912479720312\n",
            "Epoch 3 Valid Loss 2.5639919575561776 Acc 0.5979224376731302 PPL 12.987559757324153\n",
            "Epoch 4 Train Loss 2.6134993440620873 Acc 0.591683569979716 PPL 13.64672196985518\n",
            "Epoch 4 Valid Loss 2.4122349662546307 Acc 0.6137119113573407 PPL 11.15887300071354\n",
            "Epoch 5 Train Loss 2.4462493563459318 Acc 0.6072875681223882 PPL 11.544964366868209\n",
            "Epoch 5 Valid Loss 2.2914062272891442 Acc 0.6270083102493075 PPL 9.888833856319454\n",
            "Epoch 6 Train Loss 2.2988750704610426 Acc 0.6235978396343996 PPL 9.962968510975257\n",
            "Epoch 6 Valid Loss 2.20959665017445 Acc 0.6321329639889197 PPL 9.112040311846604\n",
            "Epoch 7 Train Loss 2.178947423568886 Acc 0.6358488721620763 PPL 8.83699974401879\n",
            "Epoch 7 Valid Loss 2.1383713706873793 Acc 0.6403739612188366 PPL 8.485606461602348\n",
            "Epoch 8 Train Loss 2.0698232796334395 Acc 0.6464307534397223 PPL 7.923422763942346\n",
            "Epoch 8 Valid Loss 2.0648080389420413 Acc 0.6468836565096953 PPL 7.8837843728017125\n",
            "Epoch 9 Train Loss 1.9741566953446037 Acc 0.6571323834893326 PPL 7.200544839736244\n",
            "Epoch 9 Valid Loss 2.0339124038278893 Acc 0.6558864265927978 PPL 7.64393408951091\n",
            "Epoch 10 Train Loss 1.883345155508632 Acc 0.6678389012439209 PPL 6.575464063075585\n",
            "Epoch 10 Valid Loss 1.9980029930368355 Acc 0.654224376731302 PPL 7.374314826560718\n",
            "Epoch 11 Train Loss 1.8006312446407322 Acc 0.6767711820914489 PPL 6.053467477507726\n",
            "Epoch 11 Valid Loss 1.9669876507609836 Acc 0.656786703601108 PPL 7.149108408088293\n",
            "Epoch 12 Train Loss 1.7233464652601262 Acc 0.686353527701068 PPL 5.6032481997782835\n",
            "Epoch 12 Valid Loss 1.9581498949976839 Acc 0.656994459833795 PPL 7.086204707253338\n",
            "Epoch 13 Train Loss 1.653055984270812 Acc 0.6943571446027518 PPL 5.222916614512998\n",
            "Epoch 13 Valid Loss 1.9138344872361075 Acc 0.6662049861495845 PPL 6.779033141169974\n",
            "Epoch 14 Train Loss 1.5848880606134161 Acc 0.7023900877343043 PPL 4.878745224197517\n",
            "Epoch 14 Valid Loss 1.8997704188496782 Acc 0.6666204986149584 PPL 6.6843596631272035\n",
            "Epoch 15 Train Loss 1.5210404195256526 Acc 0.7102788435690022 PPL 4.576984703023996\n",
            "Epoch 15 Valid Loss 1.8874482223036546 Acc 0.6668975069252078 PPL 6.602499056598583\n",
            "Epoch 16 Train Loss 1.4596264181531486 Acc 0.7180991715340062 PPL 4.304351200471893\n",
            "Epoch 16 Valid Loss 1.886012408046511 Acc 0.6700138504155124 PPL 6.593025896796752\n",
            "Epoch 17 Train Loss 1.3998443794499866 Acc 0.7262054302402307 PPL 4.054568943496794\n",
            "Epoch 17 Valid Loss 1.8742420663381216 Acc 0.6706371191135734 PPL 6.515878644528762\n",
            "Epoch 18 Train Loss 1.344333212089817 Acc 0.7330604364720545 PPL 3.8356281372686416\n",
            "Epoch 18 Valid Loss 1.8803092758080966 Acc 0.6704986149584488 PPL 6.55553201616195\n",
            "Epoch 19 Train Loss 1.2908815901731128 Acc 0.7397614799970674 PPL 3.635990596799412\n",
            "Epoch 19 Valid Loss 1.8856533229516153 Acc 0.6690443213296399 PPL 6.590658864475398\n",
            "--------- Translation Example 1 ---------\n",
            "SRC : ein reh springt über einen zaun .\n",
            "TRG : a deer jumps a fence .\n",
            "PRED: a pier jumps over a fence .\n",
            "--------- Translation Example 2 ---------\n",
            "SRC : ein radfahrer springt über eine hindernis .\n",
            "TRG : a biker jumps an obstacle .\n",
            "PRED: a cyclist is jumping a hurdle .\n",
            "--------- Translation Example 3 ---------\n",
            "SRC : zwei kleine kinder auf dem sand .\n",
            "TRG : two young children are on sand .\n",
            "PRED: two young children on the sand .\n",
            "--------- Translation Example 4 ---------\n",
            "SRC : ein kleiner schwarzer hund springt über <unk>\n",
            "TRG : a small black dog jumping over gates\n",
            "PRED: a small black dog jumps over some water .\n",
            "--------- Translation Example 5 ---------\n",
            "SRC : ein mann schneidet äste von bäumen .\n",
            "TRG : a man cutting branches of trees .\n",
            "PRED: a man cutting up a tree branch .\n",
            "\n",
            "BLEU: 0.3600539115895795\n",
            "\n"
          ]
        }
      ],
      "source": [
        "transformer_model = Transformer().to(device)\n",
        "run_experiment(transformer_model)\n",
        "run_translation(transformer_model, test_iter, max_len=100)\n",
        "print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook presents a comparative study of different sequence models for Neural Machine Translation from English to German, evaluated using BLEU scores and qualitative examples.\n",
        "\n",
        "**Final BLEU Scores:**\n",
        "- LSTM Seq2Seq: **0.243**\n",
        "- LSTM with Attention: **0.335**\n",
        "- Transformer: **0.360**\n",
        "\n",
        "Key takeaways:\n",
        "- Adding attention to LSTM significantly boosts performance over the baseline.\n",
        "- The Transformer model outperforms both LSTM-based models, as expected, and demonstrates superior handling of long-range dependencies.\n",
        "\n",
        "The notebook provides a clear, modular implementation pipeline that supports future experimentation (e.g., hyperparameter tuning, larger datasets, custom attention variants). Overall, the Transformer model stands out in terms of performance, but the step-by-step progression through simpler architectures offers valuable learning and insight into how neural translation systems evolve.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03507633c11c41479a89b7dca5de76fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09cfa44ea74a40a38f99741af62397c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1164a124a5444aafb3caa4836317d2ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e7c946fbd18493f9f1308088a10e396",
            "placeholder": "​",
            "style": "IPY_MODEL_ce3935ea4ba24303992213725d83d3bb",
            "value": "100%"
          }
        },
        "1833335cc42f46ec9c578c9213acd985": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bcc69d3bb614c05bd02a48b99c83425": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21cfc14cf7f24ade94663d4f8d143a3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffd59f832ea0487a853a8ad27da8659c",
            "placeholder": "​",
            "style": "IPY_MODEL_2f19fa0757744b51a7a160d68f4fe549",
            "value": "100%"
          }
        },
        "22c6e6a05f5e4db4b8f193d566e0211b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "274cd11366564e97b480bb07462460ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77c5a61b515247479c497fc697a2301c",
              "IPY_MODEL_3584f4fe82f34badafb301303d7859e3",
              "IPY_MODEL_ad8ee31568fe4d7f8ead5c253026c5ca"
            ],
            "layout": "IPY_MODEL_55e45bfd2dbe4fab82d84841575e563c"
          }
        },
        "278683c124f649c4a8d75d71791a85a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7da1c3a0497149ec981a367b2b7c6083",
            "placeholder": "​",
            "style": "IPY_MODEL_09cfa44ea74a40a38f99741af62397c6",
            "value": " 20/20 [18:44&lt;00:00, 55.85s/it]"
          }
        },
        "2af3e9e7fd804ed18073fcb8bb959ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1164a124a5444aafb3caa4836317d2ea",
              "IPY_MODEL_a26d2b5e1f714c5089fbbae79e15bcaa",
              "IPY_MODEL_e8b5dd085d6b4e9986ee2e2cf94e3eae"
            ],
            "layout": "IPY_MODEL_8fd21c14c9f74f4c8a8057726cabfcef"
          }
        },
        "2f19fa0757744b51a7a160d68f4fe549": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3584f4fe82f34badafb301303d7859e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40621c2b9bd44cef988770523680ac14",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a0104b1a9f14445b47460a095760501",
            "value": 20
          }
        },
        "40621c2b9bd44cef988770523680ac14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c3bf16542914dcfbe9bb689b9e6ba49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52c8b9f7c3a347209fb6078b76012cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55e45bfd2dbe4fab82d84841575e563c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58db2ad597c9418b990f6d936fc1b37b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a0104b1a9f14445b47460a095760501": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "61a04b5bd6ac43b29ce4dd967e8d12fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77c5a61b515247479c497fc697a2301c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1833335cc42f46ec9c578c9213acd985",
            "placeholder": "​",
            "style": "IPY_MODEL_1bcc69d3bb614c05bd02a48b99c83425",
            "value": "100%"
          }
        },
        "7da1c3a0497149ec981a367b2b7c6083": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e7c946fbd18493f9f1308088a10e396": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "863d10f457834c758e604d141ebec0af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fd21c14c9f74f4c8a8057726cabfcef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bf1a18e61e149c1b2156d6541e6eeb8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a26d2b5e1f714c5089fbbae79e15bcaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c3bf16542914dcfbe9bb689b9e6ba49",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8d179b0ac494569b88c837b95058e2b",
            "value": 20
          }
        },
        "ac048b072bba4b319bd08a92ae6d551e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21cfc14cf7f24ade94663d4f8d143a3d",
              "IPY_MODEL_b2dd3ad89b5a469781ef488c49acde84",
              "IPY_MODEL_278683c124f649c4a8d75d71791a85a5"
            ],
            "layout": "IPY_MODEL_9bf1a18e61e149c1b2156d6541e6eeb8"
          }
        },
        "ad8ee31568fe4d7f8ead5c253026c5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58db2ad597c9418b990f6d936fc1b37b",
            "placeholder": "​",
            "style": "IPY_MODEL_863d10f457834c758e604d141ebec0af",
            "value": " 20/20 [38:38&lt;00:00, 114.00s/it]"
          }
        },
        "b2dd3ad89b5a469781ef488c49acde84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61a04b5bd6ac43b29ce4dd967e8d12fa",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52c8b9f7c3a347209fb6078b76012cac",
            "value": 20
          }
        },
        "ce3935ea4ba24303992213725d83d3bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8b5dd085d6b4e9986ee2e2cf94e3eae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03507633c11c41479a89b7dca5de76fa",
            "placeholder": "​",
            "style": "IPY_MODEL_22c6e6a05f5e4db4b8f193d566e0211b",
            "value": " 20/20 [39:37&lt;00:00, 118.53s/it]"
          }
        },
        "e8d179b0ac494569b88c837b95058e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffd59f832ea0487a853a8ad27da8659c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
